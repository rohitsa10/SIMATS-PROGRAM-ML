{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdcqz6dgnawPtqccMp8wvE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohitsa10/SIMATS-PROGRAM-ML/blob/main/co5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LAB EXPERIMENT 1: Rule-Based Learning using Sequential Covering Algorithm"
      ],
      "metadata": {
        "id": "wZuGhYKNM2h1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Sequential Covering Algorithm\n",
        "data = [\n",
        "    ['Sunny','Hot','High','Weak','No'],\n",
        "    ['Sunny','Hot','High','Strong','No'],\n",
        "\n",
        "    ['Overcast','Hot','High','Weak','Yes'],\n",
        "    ['Rain','Mild','High','Weak','Yes']\n",
        "]\n",
        "rules = []\n",
        "for row in data:\n",
        "    if row[-1] == 'Yes':\n",
        "        rule = row[:-1]\n",
        "        rules.append(rule)\n",
        "print(\"Learned Rules:\")\n",
        "for r in rules:\n",
        "    print(\"IF\", r, \"THEN Yes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkGRdNzOMyfD",
        "outputId": "c0f6e290-0f59-4bdc-da36-2d0a800bf147"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned Rules:\n",
            "IF ['Overcast', 'Hot', 'High', 'Weak'] THEN Yes\n",
            "IF ['Rain', 'Mild', 'High', 'Weak'] THEN Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LAB EXPERIMENT 2: Learning Rule Sets using Decision Tree Rule Extraction"
      ],
      "metadata": {
        "id": "gf3C22N1NF3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier, export_text\n",
        "X, y = load_iris(return_X_y=True)\n",
        "model = DecisionTreeClassifier(max_depth=3)\n",
        "model.fit(X, y)\n",
        "rules = export_text(model)\n",
        "print(\"Extracted Rules:\\n\")\n",
        "print(rules)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6b4UfXANI_q",
        "outputId": "dee1da95-b92b-4042-b52d-aa7b4a66a016"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Rules:\n",
            "\n",
            "|--- feature_2 <= 2.45\n",
            "|   |--- class: 0\n",
            "|--- feature_2 >  2.45\n",
            "|   |--- feature_3 <= 1.75\n",
            "|   |   |--- feature_2 <= 4.95\n",
            "|   |   |   |--- class: 1\n",
            "|   |   |--- feature_2 >  4.95\n",
            "|   |   |   |--- class: 2\n",
            "|   |--- feature_3 >  1.75\n",
            "|   |   |--- feature_2 <= 4.85\n",
            "|   |   |   |--- class: 2\n",
            "|   |   |--- feature_2 >  4.85\n",
            "|   |   |   |--- class: 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LAB EXPERIMENT 3: Explanation-Based Learning (EBL)"
      ],
      "metadata": {
        "id": "dqGe-pq9NOQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Explanation-Based Learning Example\n",
        "def is_safe(temp, fuel):\n",
        "    return temp < 100 and fuel > 50\n",
        "example = {'temp': 80, 'fuel': 60}\n",
        "if is_safe(example['temp'], example['fuel']):\n",
        "    rule = \"IF temperature < 100 AND fuel > 50 THEN SAFE\"\n",
        "    print(\"Learned Rule:\", rule)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTpmCdxfNTM5",
        "outputId": "08a596ac-2cb7-4b12-cb1d-1b1ca8f7d119"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned Rule: IF temperature < 100 AND fuel > 50 THEN SAFE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LAB EXPERIMENT 4: Reinforcement Learning – Q-Learning Algorithm"
      ],
      "metadata": {
        "id": "eaegBXgRNX3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "states = 5\n",
        "actions = 2\n",
        "Q = np.zeros((states, actions))\n",
        "alpha = 0.1\n",
        "gamma = 0.9\n",
        "for episode in range(100):\n",
        "    state = 0\n",
        "    while state < states - 1:\n",
        "        action = np.argmax(Q[state])\n",
        "        next_state = state + 1\n",
        "\n",
        "        reward = 1 if next_state == states - 1 else 0\n",
        "        Q[state, action] += alpha * (reward + gamma * np.max(Q[next_state]) - Q[state, action])\n",
        "        state = next_state\n",
        "print(\"Q-Table:\\n\", Q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAiMi8IHNgsF",
        "outputId": "40402740-faf6-4ef2-9f72-04666515fee1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q-Table:\n",
            " [[0.7232872  0.        ]\n",
            " [0.80842464 0.        ]\n",
            " [0.89971048 0.        ]\n",
            " [0.99997344 0.        ]\n",
            " [0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LAB EXPERIMENT 5: Reinforcement Learning – Grid World Optimization"
      ],
      "metadata": {
        "id": "5Y5LVPEVNkem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "grid = np.zeros((3,3))\n",
        "Q = np.zeros((9,4))\n",
        "\n",
        "def next_state(state, action):\n",
        "    row, col = divmod(state, 3)\n",
        "    if action == 0 and row > 0: row -= 1\n",
        "    if action == 1 and row < 2: row += 1\n",
        "    if action == 2 and col > 0: col -= 1\n",
        "    if action == 3 and col < 2: col += 1\n",
        "    return row*3 + col\n",
        "\n",
        "for _ in range(200):\n",
        "    s = 0\n",
        "    while s != 8:\n",
        "        a = np.random.randint(4)\n",
        "        ns = next_state(s, a)\n",
        "        reward = 1 if ns == 8 else -0.01\n",
        "        Q[s,a] += 0.1 * (reward + 0.9 * np.max(Q[ns]) - Q[s,a])\n",
        "        s = ns\n",
        "print(\"Optimized Q-Values:\\n\", Q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KT-lem7NyaM",
        "outputId": "441d1f4e-09be-476a-e800-dcd2efd8dcc4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Q-Values:\n",
            " [[0.62149431 0.70175328 0.62150132 0.70175125]\n",
            " [0.70171423 0.79088171 0.62148892 0.79086262]\n",
            " [0.79083796 0.88992804 0.70162312 0.79067317]\n",
            " [0.62144601 0.7907952  0.70173343 0.79087912]\n",
            " [0.70155469 0.88983986 0.70164823 0.88992252]\n",
            " [0.78979474 0.99998432 0.78982308 0.88944169]\n",
            " [0.70162059 0.79044278 0.79046777 0.88986603]\n",
            " [0.79032357 0.88832237 0.7901088  0.99995502]\n",
            " [0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    }
  ]
}